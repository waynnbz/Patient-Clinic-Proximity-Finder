{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "from geopy.exc import (\n",
    "    GeocoderQueryError,\n",
    "    GeocoderQuotaExceeded,\n",
    "    ConfigurationError,\n",
    "    GeocoderParseError,\n",
    "    GeocoderTimedOut\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyAM6rMvNGdyCaJlhXvOjb_rYwqpzzKSGZ8\"\n",
    "\n",
    "COMPONENT_RESTRICTIONS = { 'country': 'CA'}\n",
    "\n",
    "P_GEO_COLS = [\"Address\", \"Postal Code\"]\n",
    "C_GEO_COLS = [\"Clinic Address\", \"Postal Code\"]\n",
    "\n",
    "N = 6\n",
    "RETRY_COUNTER_CONST = 10\n",
    "\n",
    "P_FALLBACK_SCHEMA = ['FSA', 'City', 'Province']\n",
    "C_FALLBACK_SCHEMA = ['FSA', 'Clinic City', 'Province']\n",
    "\n",
    "OUTPUT_COLS = [\"Patient_ID\",\"Pat_Geo_Cols\",\"Pat_Geocode\",\"Pat_Address\",\"Pat_Postal_Code\",\n",
    "    \"Pat_FSA\",\"Nearest_Clinic_ID\",\"Clinic_Geo_Cols\",\"Clinic_Geocode\",\n",
    "    \"Clinic_Address\",\"Clinic_Postal_Code\",\"Clinic_FSA\",\"Clinic_Distance\"]\n",
    "    \n",
    "DEFAULT_LOC = [43.6532, 79.3832]\n",
    "DEFAULT_DIST = 9999\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(P_FILE, C_FILE):\n",
    "    try:\n",
    "        p_df = pd.read_csv(P_FILE)\n",
    "        c_df = pd.read_csv(C_FILE)\n",
    "    except:\n",
    "        print(\"Fail to load data, please check input data path is correct\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return p_df, c_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy\n",
    "from geopy.geocoders import GoogleV3\n",
    "from functools import partial \n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_address_list(r, Geo_Cols, schema):\n",
    "    '''\n",
    "    Generate a list of fallback address list in the order per schema\n",
    "    '''\n",
    "    address_list = []\n",
    "    \n",
    "    address = \"\"\n",
    "    for c in Geo_Cols.split(','):\n",
    "        if not address:\n",
    "            address += r[c]\n",
    "        else:\n",
    "            address += \", \" + r[c]\n",
    "            \n",
    "    address_list.append(address)\n",
    "    \n",
    "    for cc in schema:\n",
    "        address_list.append(r[cc])\n",
    "    \n",
    "    return address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_address(geo_locator, address_list, retry_counter=1):\n",
    "    '''\n",
    "    Request GoogleV3 service for geocode data\n",
    "    Exceptions are caught and handled\n",
    "        - if Connection Error, retry $RETRY_COUNTER_CONST times\n",
    "        - otherwise fall back to next precision level address and request the geolocation again\n",
    "    Inputs: geo_locator: GoogleV3 geocoder\n",
    "            address_list: a fall back address list in precision order, most precise address at position 0\n",
    "            retry_counter: initial retry value\n",
    "    Outputs: location_result: Geocoded lat/lng values received from the server\n",
    "                            *note: if all precision level failed to retrive a valid data, return DEFAULT_LOC\n",
    "            al: final state of address fallback list, according its consumed level, \n",
    "                assign the corresponding Geo_Cols info to the dataframe\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # default case if exhuasted the fallback list still no location found\n",
    "        if not address_list:\n",
    "            al = address_list\n",
    "            return DEFAULT_LOC, al\n",
    "\n",
    "        # the geopy GoogleV3 geocoding call\n",
    "        location = geo_locator(address_list[0])\n",
    "        \n",
    "        if location is not None:\n",
    "            location_result = tuple(location.point[:2])\n",
    "            al = address_list\n",
    "#             print(f'location : {location}, al: {al}')\n",
    "        else:\n",
    "            location_result, al = geocode_address(geo_locator, address_list[1:], retry_counter)\n",
    "\n",
    "    # To catch generic geocoder errors.\n",
    "    except (ValueError, GeocoderQuotaExceeded, ConfigurationError, GeocoderParseError) as error:\n",
    "        if hasattr(error, 'message'):\n",
    "            error_message = error.message\n",
    "        else:\n",
    "            error_message = error\n",
    "        print(error_message)\n",
    "        lcoation_result, al = geocode_address(geo_locator, address_list[1:], retry_counter)\n",
    "    # To retry because intermittent failures and timeout sometimes occurs\n",
    "    except (GeocoderTimedOut, GeocoderQueryError) as geocodingerror:\n",
    "        if retry_counter < RETRY_COUNTER_CONST:\n",
    "            print(f'Retrying {retry_counter} time(s) ' )\n",
    "            return geocode_address(geo_locator, address_list, retry_counter+1)\n",
    "        else:\n",
    "            if hasattr(geocodingerror, 'message'):\n",
    "                error_message = geocodingerror.message\n",
    "            else:\n",
    "                error_message = geocodingerror\n",
    "            print(error_message)\n",
    "            location_result, al = geocode_address(geo_locator, address_list[1:], retry_counter)\n",
    "    # To retry because intermittent failures and timeout sometimes occurs\n",
    "    except BaseException as error:\n",
    "        if retry_counter < RETRY_COUNTER_CONST:\n",
    "#             time.sleep(5)\n",
    "            print(f'Retrying {retry_counter} time(s) ')\n",
    "            return geocode_address(geo_locator, address_list, retry_counter+1)\n",
    "        else:\n",
    "            print(error)\n",
    "            location_result, al = geocode_address(geo_locator, address_list[1:], retry_counter)\n",
    "\n",
    "    return location_result, al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_files(P_df, C_df, output_path):\n",
    "    '''\n",
    "    Calling geocode_address function and adding corresponding result cols\n",
    "    Outputs: processed Patients & Clinics dataframes\n",
    "    '''\n",
    "    \n",
    "    geocoder = GoogleV3(api_key=API_KEY)\n",
    "    geo_locator = partial(geocoder.geocode, components=COMPONENT_RESTRICTIONS)\n",
    "    \n",
    "    P_df[\"Pat_Geo_Cols\"] = \",\".join(map(str, P_GEO_COLS))\n",
    "    C_df[\"Clinic_Geo_Cols\"] = \",\".join(map(str, C_GEO_COLS))\n",
    "    \n",
    "    P_df[\"Pat_Geocode\"] = ''\n",
    "    C_df[\"Clinic_Geocode\"] = ''\n",
    "    \n",
    "    # geocode addresses by rows and modifies 'Geo_Cols' if needed\n",
    "    for i,p_r in P_df.iterrows():\n",
    "        p_address_list = generate_address_list(p_r, p_r[\"Pat_Geo_Cols\"], P_FALLBACK_SCHEMA)\n",
    "        \n",
    "        P_df.at[i, \"Pat_Geocode\"], p_al = geocode_address(geo_locator, p_address_list)#, retry_counter=1)\n",
    "        if len(p_al) != len(p_address_list):\n",
    "            P_df.at[i, \"Pat_Geo_Cols\"] = P_FALLBACK_SCHEMA[-len(p_al)] if len(p_al) else \"DEFAULT_LOC\"\n",
    "            \n",
    "    for i,c_r in C_df.iterrows():\n",
    "        c_address_list = generate_address_list(c_r, c_r[\"Clinic_Geo_Cols\"], C_FALLBACK_SCHEMA)\n",
    "        \n",
    "        C_df.at[i, \"Clinic_Geocode\"], c_al = geocode_address(geo_locator, c_address_list)#, retry_counter=1)\n",
    "        if len(c_al) != len(c_address_list):\n",
    "            C_df.at[i, \"Clinic_Geo_Cols\"] = C_FALLBACK_SCHEMA[-len(c_al)] if len(c_al) else \"DEFAULT_LOC\"\n",
    "            \n",
    "    # output processed dataframes\n",
    "    try:\n",
    "        if not os.path.isdir(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        P_df.to_csv(os.path.join(output_path, 'P_df.csv'), index=False)\n",
    "        C_df.to_csv(os.path.join(output_path, 'C_df.csv'), index=False)\n",
    "    except:\n",
    "        print(\"Fail to output processed Patients & Clinics dataframes, please check the output path is corret\")\n",
    "    \n",
    "    return P_df, C_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy import distance\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_travel_dist(gmaps, P_node, C_node, retry_counter=1):\n",
    "    '''\n",
    "    apply gmaps Google Distance matrix API to find the nearest one with shortest travel distance\n",
    "    Inputs: P_node: target patient node\n",
    "            C_node: Client node\n",
    "    Output: dist: shortest travel distance\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        # the gmaps api call\n",
    "        dist = gmaps.distance_matrix(P_node, C_node, mode='driving')\n",
    "        \n",
    "        if dist is not None:\n",
    "            # locate the distance value from returned string\n",
    "            dist_result = dist[\"rows\"][0][\"elements\"][0][\"distance\"][\"value\"]/1000\n",
    "        else:\n",
    "            #if API server fails all, travel distances will set to the same default value\n",
    "            # later the one with shorter geodesic distance will be picked\n",
    "            dist_result = DEFAULT_DIST\n",
    "     \n",
    "    # To catch generic geocoder errors.\n",
    "    except (ValueError, GeocoderQuotaExceeded, ConfigurationError, GeocoderParseError) as error:\n",
    "        if hasattr(error, 'message'):\n",
    "            error_message = error.message\n",
    "        else:\n",
    "            error_message = error\n",
    "        print(error_message)\n",
    "        dist_result = DEFAULT_DIST\n",
    "    # To retry because intermittent failures and timeout sometimes occurs\n",
    "    except (GeocoderTimedOut, GeocoderQueryError) as geocodingerror:\n",
    "        if retry_counter < RETRY_COUNTER_CONST:\n",
    "            print(f'Retrying {retry_counter} time(s)' )\n",
    "            return get_travel_dist(P_node, C_node, retry_counter+1)\n",
    "        else:\n",
    "            if hasattr(geocodingerror, 'message'):\n",
    "                error_message = geocodingerror.message\n",
    "            else:\n",
    "                error_message = geocodingerror\n",
    "            print(error_message)\n",
    "            dist_result = DEFAULT_DIST\n",
    "    # To retry because intermittent failures and timeout sometimes occurs\n",
    "    except BaseException as error:\n",
    "        if retry_counter < RETRY_COUNTER_CONST:\n",
    "#             time.sleep(5)\n",
    "            print(f'Retrying {retry_counter} time(s)')\n",
    "            return get_travel_dist(P_node, C_node, retry_counter+1)\n",
    "        else:\n",
    "            print(error)\n",
    "            dist_result = DEFAULT_DIST\n",
    "    \n",
    "    return dist_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_files(P_df, C_df, output_path):\n",
    "    \n",
    "    '''\n",
    "    first using geodesic to filter out N nearest locations\n",
    "    then apply google distance matrix to compute the travel distance\n",
    "    '''\n",
    "    # cols mapping\n",
    "    PC_mapped = pd.DataFrame(columns = OUTPUT_COLS)\n",
    "    PC_mapped[\"Patient_ID\"] = P_df[\"ID\"]\n",
    "    PC_mapped[\"Pat_Geo_Cols\"] = P_df[\"Pat_Geo_Cols\"]\n",
    "    PC_mapped[\"Pat_Geocode\"] = P_df[\"Pat_Geocode\"]\n",
    "    PC_mapped[\"Pat_Address\"] = P_df[\"Address\"]\n",
    "    PC_mapped[\"Pat_Postal_Code\"] = P_df[\"Postal Code\"]\n",
    "    PC_mapped[\"Pat_FSA\"] = P_df[\"FSA\"]\n",
    "    \n",
    "    # initialize the distance API\n",
    "    gmaps = googlemaps.Client(key=API_KEY)\n",
    "    \n",
    "    for i, p_r, in PC_mapped.iterrows():\n",
    "        # target patient node\n",
    "        P_node = p_r['Pat_Geocode']\n",
    "        \n",
    "        # target pool of N locations with neareset geodesic distance\n",
    "        C_df['dist'] = C_df['Clinic_Geocode'].apply(lambda p : distance.geodesic(P_node, p).km)\n",
    "        N_pool = C_df.nsmallest(N, 'dist', keep='all').reset_index()\n",
    "        \n",
    "        N_pool['travel_dist'] = ''\n",
    "        \n",
    "        # function that call the Google distance matrix API\n",
    "        for n_i, r in N_pool.iterrows():\n",
    "            N_pool.at[n_i,'travel_dist'] = get_travel_dist(gmaps, P_node, r[\"Clinic_Geocode\"])\n",
    "        \n",
    "        # pick the one with smallest travel_dist, in case of duplicate, keep the first \n",
    "        # thus the one with shorter geodesic distance will be picked\n",
    "        N_pool['travel_dist'] = N_pool['travel_dist'].apply(np.float)\n",
    "        Nearest = N_pool.nsmallest(1, 'travel_dist', keep='first')\n",
    "\n",
    "        PC_mapped.at[i, \"Nearest_Clinic_ID\"] = Nearest[\"Clinic ID\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_Geo_Cols\"] = Nearest[\"Clinic_Geo_Cols\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_Geocode\"] = Nearest[\"Clinic_Geocode\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_Address\"] = Nearest[\"Clinic Address\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_Postal_Code\"] = Nearest[\"Postal Code\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_FSA\"] = Nearest[\"FSA\"].values[0]\n",
    "        PC_mapped.at[i, \"Clinic_Distance\"] = Nearest[\"travel_dist\"].values[0]\n",
    "       \n",
    "        \n",
    "    # output final mapped dataframes\n",
    "    try:\n",
    "        if not os.path.isdir(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        PC_mapped.to_csv(os.path.join(output_path, 'PC_mapped.csv'), index=False)\n",
    "    except:\n",
    "        print(\"Fail to output final Mapped dataframes, please check the output path is corret\")\n",
    "    \n",
    "    return PC_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import click\n",
    "\n",
    "# @click.command()\n",
    "# @click.option('patients_file', '--patients', default='./data/patients.csv', type=click.Path(exists=True),\n",
    "#              help='Patients.csv file path')\n",
    "# @click.option('clinics_file', '--clinics', default='./data/clinics.csv', type=click.Path(exists=True),\n",
    "#              help='Clinics.csv file path')\n",
    "# @click.option('output_path', '--output', default='./output', type=click.Path(),\n",
    "#              help='Output directory')\n",
    "# def main(patients_file, clinics_file, output_path):\n",
    "    \n",
    "#     click.echo('Loading data files...')\n",
    "#     P_df, C_df = load_files(patients_file, clinics_file)\n",
    "    \n",
    "#     click.echo('Geocoding...')\n",
    "#     P_df, C_df = geocode_files(P_df, C_df, output_path)\n",
    "    \n",
    "#     click.echo('Calculating travel distance and matching...')\n",
    "#     PC_mapped = map_files(P_df, C_df, output_path)\n",
    "\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_file = './data/patients.csv'\n",
    "clinics_file = './data/clinics.csv'\n",
    "output_path = './output'\n",
    "\n",
    "\n",
    "# P_df, C_df = load_files(patients_file, clinics_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='maps.googleapis.com', port=443): Read timed out. (read timeout=1)\")': /maps/api/geocode/json?sensor=false&address=722+85+ST+SW+UNIT+215%2C+T3H+1S6&key=AIzaSyAM6rMvNGdyCaJlhXvOjb_rYwqpzzKSGZ8&components=country%3ACA\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='maps.googleapis.com', port=443): Read timed out. (read timeout=1)\")': /maps/api/geocode/json?sensor=false&address=722+85+ST+SW+UNIT+215%2C+T3H+1S6&key=AIzaSyAM6rMvNGdyCaJlhXvOjb_rYwqpzzKSGZ8&components=country%3ACA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrying 1 time(s) \n",
      "Retrying 1 time(s) \n",
      "Retrying 2 time(s) \n",
      "Retrying 3 time(s) \n"
     ]
    }
   ],
   "source": [
    "P_df, C_df = geocode_files(P_df, C_df, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-539253c15203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mP_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'P_df' is not defined"
     ]
    }
   ],
   "source": [
    "P_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df = pd.read_csv('./output/P_df.csv', converters={'Pat_Geocode': ast.literal_eval})\n",
    "C_df = pd.read_csv('./output/C_df.csv', converters={'Clinic_Geocode': ast.literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC_mapped = map_files(P_df.iloc[11:12, :], C_df, './output')\n",
    "nearest = map_files(P_df, C_df, './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
